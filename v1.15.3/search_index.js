var documenterSearchIndex = {"docs":
[{"location":"limits/#Limitations-of-ReverseDiff","page":"Limitation of ReverseDiff","title":"Limitations of ReverseDiff","text":"","category":"section"},{"location":"limits/","page":"Limitation of ReverseDiff","title":"Limitation of ReverseDiff","text":"ReverseDiff works by injecting user code with new number types that record all operations that occur on them, accumulating an execution trace of the target function which can be re-run forwards and backwards to propagate new input values and derivative information. Naturally, this technique has some limitations. Here's a list of all the roadblocks we've seen users run into (\"target function\" here refers to the function being differentiated):","category":"page"},{"location":"limits/","page":"Limitation of ReverseDiff","title":"Limitation of ReverseDiff","text":"The target function can only be composed of generic Julia functions. ReverseDiff cannot propagate derivative information through non-Julia code. Thus, your function may not work if it makes calls to external, non-Julia programs, e.g. uses explicit BLAS calls instead of Ax_mul_Bx-style functions.\nThe target function must be written generically enough to accept numbers of type T<:Real as input (or arrays of these numbers). The function doesn't require a specific type signature, as long as the type signature is generic enough to avoid breaking this rule. This also means that any storage assigned used within the function must be generic as well.\nNested differentiation of closures is dangerous. Differentiating closures is safe, and nested differentation is safe, but you might be vulnerable to a subtle bug if you try to do both. See this ForwardDiff issue for details. A fix is currently being planned for this problem.\nArray input types must obey A<:AbstractArray and Base.IndexStyle(::A) == Base.IndexLinear().\nArray inputs that are being differentiated cannot be mutated. This also applies to any \"descendent\" arrays that must be tracked (e.g. if A is an immutable input array, then C = A * A will also be immutable). If you try to perform setindex! on such arrays, an error will be thrown. In the future, this restriction might be lifted. Note that arrays explicitly constructed within the target function (e.g. via ones, similar, etc.) can be mutated, as well as output arrays used when taking the Jacobian of a function of the form f!(output, input....).","category":"page"},{"location":"api/#ReverseDiff-API","page":"API","title":"ReverseDiff API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"CurrentModule = ReverseDiff","category":"page"},{"location":"api/#Gradients-of-f(x::AbstractArray{:Real}...)::Real","page":"API","title":"Gradients of f(x::AbstractArray{<:Real}...)::Real","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"ReverseDiff.gradient\nReverseDiff.gradient!","category":"page"},{"location":"api/#ReverseDiff.gradient","page":"API","title":"ReverseDiff.gradient","text":"ReverseDiff.gradient(f, input, cfg::GradientConfig = GradientConfig(input))\n\nIf input is an AbstractArray, assume f has the form f(::AbstractArray{<:Real})::Real and return ∇f(input).\n\nIf input is a tuple of AbstractArrays, assume f has the form f(::AbstractArray{<:Real}...)::Real (such that it can be called as f(input...)) and return a Tuple where the ith element is the gradient of f w.r.t. input[i].\n\nNote that cfg can be preallocated and reused for subsequent calls.\n\nIf possible, it is highly recommended to use ReverseDiff.GradientTape to prerecord f. Otherwise, this method will have to re-record f's execution trace for every subsequent call.\n\n\n\n\n\n","category":"function"},{"location":"api/#ReverseDiff.gradient!","page":"API","title":"ReverseDiff.gradient!","text":"ReverseDiff.gradient!(result, f, input, cfg::GradientConfig = GradientConfig(input))\n\nReturns result. This method is exactly like ReverseDiff.gradient(f, input, cfg), except it stores the resulting gradient(s) in result rather than allocating new memory.\n\nresult can be an AbstractArray or a Tuple of AbstractArrays. The result (or any of its elements, if isa(result, Tuple)), can also be a DiffResults.DiffResult, in which case the primal value f(input) (or f(input...), if isa(input, Tuple)) will be stored in it as well.\n\n\n\n\n\nReverseDiff.gradient!(tape::Union{GradientTape,CompiledGradient}, input)\n\nIf input is an AbstractArray, assume tape represents a function of the form f(::AbstractArray)::Real and return ∇f(input).\n\nIf input is a tuple of AbstractArrays, assume tape represents a function of the form f(::AbstractArray...)::Real and return a Tuple where the ith element is the gradient of f w.r.t. input[i].\n\n\n\n\n\nReverseDiff.gradient!(result, tape::Union{GradientTape,CompiledGradient}, input)\n\nReturns result. This method is exactly like ReverseDiff.gradient!(tape, input), except it stores the resulting gradient(s) in result rather than allocating new memory.\n\nresult can be an AbstractArray or a Tuple of AbstractArrays. The result (or any of its elements, if isa(result, Tuple)), can also be a DiffResults.DiffResult, in which case the primal value f(input) (or f(input...), if isa(input, Tuple)) will be stored in it as well.\n\n\n\n\n\n","category":"function"},{"location":"api/#Jacobians-of-f(x::AbstractArray{:Real}...)::AbstractArray{:Real}","page":"API","title":"Jacobians of f(x::AbstractArray{<:Real}...)::AbstractArray{<:Real}","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"ReverseDiff.jacobian\nReverseDiff.jacobian!","category":"page"},{"location":"api/#ReverseDiff.jacobian","page":"API","title":"ReverseDiff.jacobian","text":"ReverseDiff.jacobian(f, input, cfg::JacobianConfig = JacobianConfig(input))\n\nIf input is an AbstractArray, assume f has the form f(::AbstractArray{<:Real})::AbstractArray{<:Real} and return J(f)(input).\n\nIf input is a tuple of AbstractArrays, assume f has the form f(::AbstractArray{<:Real}...)::AbstractArray{<:Real} (such that it can be called as f(input...)) and return a Tuple where the ith element is the  Jacobian of f w.r.t. input[i].\n\nNote that cfg can be preallocated and reused for subsequent calls.\n\nIf possible, it is highly recommended to use ReverseDiff.JacobianTape to prerecord f. Otherwise, this method will have to re-record f's execution trace for every subsequent call.\n\n\n\n\n\nReverseDiff.jacobian(f!, output, input, cfg::JacobianConfig = JacobianConfig(output, input))\n\nExactly like ReverseDiff.jacobian(f, input, cfg), except the target function has the form f!(output::AbstractArray{<:Real}, input::AbstractArray{<:Real}...).\n\n\n\n\n\n","category":"function"},{"location":"api/#ReverseDiff.jacobian!","page":"API","title":"ReverseDiff.jacobian!","text":"ReverseDiff.jacobian!(result, f, input, cfg::JacobianConfig = JacobianConfig(input))\n\nReturns result. This method is exactly like ReverseDiff.jacobian(f, input, cfg), except it stores the resulting Jacobian(s) in result rather than allocating new memory.\n\nresult can be an AbstractArray or a Tuple of AbstractArrays. The result (or any of its elements, if isa(result, Tuple)), can also be a DiffResults.DiffResult, in which case the primal value f(input) (or f(input...), if isa(input, Tuple)) will be stored in it as well.\n\n\n\n\n\nReverseDiff.jacobian!(result, f!, output, input, cfg::JacobianConfig = JacobianConfig(output, input))\n\nExactly like ReverseDiff.jacobian!(result, f, input, cfg), except the target function has the form f!(output::AbstractArray{<:Real}, input::AbstractArray{<:Real}...).\n\n\n\n\n\nReverseDiff.jacobian!(tape::Union{JacobianTape,CompiledJacobian}, input)\n\nIf input is an AbstractArray, assume tape represents a function of the form f(::AbstractArray{<:Real})::AbstractArray{<:Real} or f!(::AbstractArray{<:Real}, ::AbstractArray{<:Real}) and return tape's Jacobian w.r.t. input.\n\nIf input is a tuple of AbstractArrays, assume tape represents a function of the form f(::AbstractArray{<:Real}...)::AbstractArray{<:Real} or f!(::AbstractArray{<:Real}, ::AbstractArray{<:Real}...) and return a Tuple where the ith element is tape's Jacobian w.r.t. input[i].\n\nNote that if tape represents a function of the form f!(output, input...), you can only execute tape with new input values. There is no way to re-run tape's tape with new output values; since f! can mutate output, there exists no stable \"hook\" for loading new output values into the tape.\n\n\n\n\n\nReverseDiff.jacobian!(result, tape::Union{JacobianTape,CompiledJacobian}, input)\n\nReturns result. This method is exactly like ReverseDiff.jacobian!(tape, input), except it stores the resulting Jacobian(s) in result rather than allocating new memory.\n\nresult can be an AbstractArray or a Tuple of AbstractArrays. The result (or any of its elements, if isa(result, Tuple)), can also be a DiffResults.DiffResult, in which case the primal value of the target function will be stored in it as well.\n\n\n\n\n\n","category":"function"},{"location":"api/#Hessians-of-f(x::AbstractArray{:Real})::Real","page":"API","title":"Hessians of f(x::AbstractArray{<:Real})::Real","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"ReverseDiff.hessian\nReverseDiff.hessian!","category":"page"},{"location":"api/#ReverseDiff.hessian","page":"API","title":"ReverseDiff.hessian","text":"ReverseDiff.hessian(f, input::AbstractArray, cfg::HessianConfig = HessianConfig(input))\n\nGiven f(input::AbstractArray{<:Real})::Real, return fs Hessian w.r.t. to the given input.\n\nNote that cfg can be preallocated and reused for subsequent calls.\n\nIf possible, it is highly recommended to use ReverseDiff.HessianTape to prerecord f. Otherwise, this method will have to re-record f's execution trace for every subsequent call.\n\n\n\n\n\n","category":"function"},{"location":"api/#ReverseDiff.hessian!","page":"API","title":"ReverseDiff.hessian!","text":"ReverseDiff.hessian!(result::AbstractArray, f, input::AbstractArray, cfg::HessianConfig = HessianConfig(input))\n\nReverseDiff.hessian!(result::DiffResult, f, input::AbstractArray, cfg::HessianConfig = HessianConfig(result, input))\n\nReturns result. This method is exactly like ReverseDiff.hessian(f, input, cfg), except it stores the resulting Hessian in result rather than allocating new memory.\n\nIf result is a DiffResults.DiffResult, the primal value f(input) and the gradient ∇f(input) will be stored in it along with the Hessian H(f)(input).\n\n\n\n\n\nReverseDiff.hessian!(tape::Union{HessianTape,CompiledHessian}, input)\n\nAssuming tape represents a function of the form f(::AbstractArray{<:Real})::Real, return the Hessian H(f)(input).\n\n\n\n\n\nReverseDiff.hessian!(result::AbstractArray, tape::Union{HessianTape,CompiledHessian}, input)\n\nReverseDiff.hessian!(result::DiffResult, tape::Union{HessianTape,CompiledHessian}, input)\n\nReturns result. This method is exactly like ReverseDiff.hessian!(tape, input), except it stores the resulting Hessian in result rather than allocating new memory.\n\nIf result is a DiffResults.DiffResult, the primal value f(input) and the gradient ∇f(input) will be stored in it along with the Hessian H(f)(input).\n\n\n\n\n\n","category":"function"},{"location":"api/#The-AbstractTape-API","page":"API","title":"The AbstractTape API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"ReverseDiff works by recording the target function's execution trace to a \"tape\", then running the tape forwards and backwards to propagate new input values and derivative information.","category":"page"},{"location":"api/","page":"API","title":"API","text":"In many cases, it is the recording phase of this process that consumes the most time and memory, while the forward and reverse execution passes are often fast and non-allocating. Luckily, ReverseDiff provides the AbstractTape family of types, which enable the user to pre-record a reusable tape for a given function and differentiation operation.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Note that pre-recording a tape can only capture the the execution trace of the target function with the given input values. Therefore, re-running the tape (even with new input values) will only execute the paths that were recorded using the original input values. In other words, the tape cannot any re-enact branching behavior that depends on the input values. You can guarantee your own safety in this regard by never using the AbstractTape API with functions that contain control flow based on the input values.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Similarly to the branching issue, a tape is not guaranteed to capture any side-effects caused or depended on by the target function.","category":"page"},{"location":"api/","page":"API","title":"API","text":"ReverseDiff.GradientTape\nReverseDiff.JacobianTape\nReverseDiff.HessianTape\nReverseDiff.compile","category":"page"},{"location":"api/#ReverseDiff.GradientTape","page":"API","title":"ReverseDiff.GradientTape","text":"ReverseDiff.GradientTape(f, input, cfg::GradientConfig = GradientConfig(input))\n\nReturn a GradientTape instance containing a pre-recorded execution trace of f at the given input.\n\nThis GradientTape can then be passed to ReverseDiff.gradient! to take gradients of the execution trace with new input values. Note that these new values must have the same element type and shape as input.\n\nSee ReverseDiff.gradient for a description of acceptable types for input.\n\n\n\n\n\n","category":"type"},{"location":"api/#ReverseDiff.JacobianTape","page":"API","title":"ReverseDiff.JacobianTape","text":"ReverseDiff.JacobianTape(f, input, cfg::JacobianConfig = JacobianConfig(input))\n\nReturn a JacobianTape instance containing a pre-recorded execution trace of f at the given input.\n\nThis JacobianTape can then be passed to ReverseDiff.jacobian! to take Jacobians of the execution trace with new input values. Note that these new values must have the same element type and shape as input.\n\nSee ReverseDiff.jacobian for a description of acceptable types for input.\n\n\n\n\n\nReverseDiff.JacobianTape(f!, output, input, cfg::JacobianConfig = JacobianConfig(output, input))\n\nReturn a JacobianTape instance containing a pre-recorded execution trace of f at the given output and input.\n\nThis JacobianTape can then be passed to ReverseDiff.jacobian! to take Jacobians of the execution trace with new input values. Note that these new values must have the same element type and shape as input.\n\nSee ReverseDiff.jacobian for a description of acceptable types for input.\n\n\n\n\n\n","category":"type"},{"location":"api/#ReverseDiff.HessianTape","page":"API","title":"ReverseDiff.HessianTape","text":"ReverseDiff.HessianTape(f, input, cfg::HessianConfig = HessianConfig(input))\n\nReturn a HessianTape instance containing a pre-recorded execution trace of f at the given input.\n\nThis HessianTape can then be passed to ReverseDiff.hessian! to take Hessians of the execution trace with new input values. Note that these new values must have the same element type and shape as input.\n\nSee ReverseDiff.hessian for a description of acceptable types for input.\n\n\n\n\n\n","category":"type"},{"location":"api/#ReverseDiff.compile","page":"API","title":"ReverseDiff.compile","text":"ReverseDiff.compile(t::AbstractTape)\n\nReturn a fully compiled representation of t of type CompiledTape. This object can be passed to any API methods that accept t (e.g. gradient!(result, t, input)).\n\nIn many cases, compiling t can significantly speed up execution time. Note that the longer the tape, the more time compilation may take. Very long tapes (i.e. when length(t) is on the order of 10000 elements) can take a very long time to compile.\n\n\n\n\n\n","category":"function"},{"location":"api/#The-AbstractConfig-API","page":"API","title":"The AbstractConfig API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"For the sake of convenience and performance, all \"extra\" information used by ReverseDiff's API methods is bundled up in the ReverseDiff.AbstractConfig family of types. These types allow the user to easily feed several different parameters to ReverseDiff's API methods, such as work buffers and tape configurations.","category":"page"},{"location":"api/","page":"API","title":"API","text":"ReverseDiff's basic API methods will allocate these types automatically by default, but you can reduce memory usage and improve performance if you preallocate them yourself.","category":"page"},{"location":"api/","page":"API","title":"API","text":"ReverseDiff.GradientConfig\nReverseDiff.JacobianConfig\nReverseDiff.HessianConfig","category":"page"},{"location":"api/#ReverseDiff.GradientConfig","page":"API","title":"ReverseDiff.GradientConfig","text":"ReverseDiff.GradientConfig(input, tp::InstructionTape = InstructionTape())\n\nReturn a GradientConfig instance containing the preallocated tape and work buffers used by the ReverseDiff.gradient/ReverseDiff.gradient! methods.\n\nNote that input is only used for type and shape information; it is not stored or modified in any way. It is assumed that the element type of input is same as the element type of the target function's output.\n\nSee ReverseDiff.gradient for a description of acceptable types for input.\n\n\n\n\n\nReverseDiff.GradientConfig(input, ::Type{D}, tp::InstructionTape = InstructionTape())\n\nLike GradientConfig(input, tp), except the provided type D is assumed to be the element type of the target function's output.\n\n\n\n\n\n","category":"type"},{"location":"api/#ReverseDiff.JacobianConfig","page":"API","title":"ReverseDiff.JacobianConfig","text":"ReverseDiff.JacobianConfig(input, tp::InstructionTape = InstructionTape())\n\nReturn a JacobianConfig instance containing the preallocated tape and work buffers used by the ReverseDiff.jacobian/ReverseDiff.jacobian! methods.\n\nNote that input is only used for type and shape information; it is not stored or modified in any way. It is assumed that the element type of input is same as the element type of the target function's output.\n\nSee ReverseDiff.jacobian for a description of acceptable types for input.\n\nReverseDiff.JacobianConfig(input, ::Type{D}, tp::InstructionTape = InstructionTape())\n\nLike JacobianConfig(input, tp), except the provided type D is assumed to be the element type of the target function's output.\n\n\n\n\n\nReverseDiff.JacobianConfig(output::AbstractArray, input, tp::InstructionTape = InstructionTape())\n\nReturn a JacobianConfig instance containing the preallocated tape and work buffers used by the ReverseDiff.jacobian/ReverseDiff.jacobian! methods. This method assumes the target function has the form f!(output, input)\n\nNote that input and output are only used for type and shape information; they are not stored or modified in any way.\n\nSee ReverseDiff.jacobian for a description of acceptable types for input.\n\n\n\n\n\nReverseDiff.JacobianConfig(result::DiffResults.DiffResult, input, tp::InstructionTape = InstructionTape())\n\nA convenience method for JacobianConfig(DiffResults.value(result), input, tp).\n\n\n\n\n\n","category":"type"},{"location":"api/#ReverseDiff.HessianConfig","page":"API","title":"ReverseDiff.HessianConfig","text":"ReverseDiff.HessianConfig(input::AbstractArray, gtp::InstructionTape = InstructionTape(), jtp::InstructionTape = InstructionTape())\n\nReturn a HessianConfig instance containing the preallocated tape and work buffers used by the ReverseDiff.hessian/ReverseDiff.hessian! methods. gtp is the tape used for the inner gradient calculation, while jtp is used for outer Jacobian calculation.\n\nNote that input is only used for type and shape information; it is not stored or modified in any way. It is assumed that the element type of input is same as the element type of the target function's output.\n\n\n\n\n\nReverseDiff.HessianConfig(input::AbstractArray, ::Type{D}, gtp::InstructionTape = InstructionTape(), jtp::InstructionTape = InstructionTape())\n\nLike HessianConfig(input, tp), except the provided type D is assumed to be the element type of the target function's output.\n\n\n\n\n\nReverseDiff.HessianConfig(result::DiffResults.DiffResult, input::AbstractArray, gtp::InstructionTape = InstructionTape(), jtp::InstructionTape = InstructionTape())\n\nLike HessianConfig(input, tp), but utilize result along with input to construct work buffers.\n\nNote that result and input are only used for type and shape information; they are not stored or modified in any way.\n\n\n\n\n\n","category":"type"},{"location":"api/#Optimization-Annotations","page":"API","title":"Optimization Annotations","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"ReverseDiff.@forward\nReverseDiff.@skip","category":"page"},{"location":"api/#ReverseDiff.@forward","page":"API","title":"ReverseDiff.@forward","text":"ReverseDiff.@forward(f)(args::Real...)\nReverseDiff.@forward f(args::Real...) = ...\nReverseDiff.@forward f = (args::Real...) -> ...\n\nDeclare that the given function should be differentiated using forward mode automatic differentiation. Note that the macro can be used at either the definition site or at the call site of f. Currently, only length(args) <= 2 is supported. Note that, if f is defined within another function g, f should not close over any differentiable input of g. By using this macro, you are providing a guarantee that this property holds true.\n\nThis macro can be very beneficial for performance when intermediate functions in your computation are low dimensional scalar functions, because it minimizes the number of instructions that must be recorded to the tape. For example, take the function sigmoid(n) = 1. / (1. + exp(-n)). Normally, using ReverseDiff to differentiate this function would require recording 4 instructions (-, exp, +, and /). However, if we apply the @forward macro, only one instruction will be recorded (sigmoid). The sigmoid function will then be differentiated using ForwardDiff's Dual number type.\n\nThis is also beneficial for higher-order elementwise function application. ReverseDiff overloads map/broadcast to dispatch on @forward-applied functions. For example, map(@forward(f), x) will usually be more performant than map(f, x).\n\nReverseDiff overloads many Base scalar functions to behave as @forward functions by default. A full list is given by DiffRules.diffrules().\n\n\n\n\n\n","category":"macro"},{"location":"api/#ReverseDiff.@skip","page":"API","title":"ReverseDiff.@skip","text":"ReverseDiff.@skip(f)(args::Real...)\nReverseDiff.@skip f(args::Real...) = ...\nReverseDiff.@skip f = (args::Real...) -> ...\n\nDeclare that the given function should be skipped during the instruction-recording phase of differentiation. Note that the macro can be used at either the definition site or at the call site of f. Note that, if f is defined within another function g, f should not close over any differentiable input of g. By using this macro, you are providing a guarantee that this property holds true.\n\nReverseDiff overloads many Base scalar functions to behave as @skip functions by default. A full list is given by ReverseDiff.SKIPPED_UNARY_SCALAR_FUNCS and ReverseDiff.SKIPPED_BINARY_SCALAR_FUNCS.\n\n\n\n\n\n","category":"macro"},{"location":"api/#ChainRules-integration","page":"API","title":"ChainRules integration","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"ReverseDiff.@grad_from_chainrules","category":"page"},{"location":"api/#ReverseDiff.@grad_from_chainrules","page":"API","title":"ReverseDiff.@grad_from_chainrules","text":"@grad_from_chainrules f(args...; kwargs...)\n\nThe @grad_from_chainrules macro provides a way to import adjoints(rrule) defined in ChainRules to ReverseDiff. One must provide a method signature to import the corresponding rrule. In the provided method signature, one should replace the types of arguments to which one wants to take derivatives with respect with ReverseDiff.TrackedReal and ReverseDiff.TrackedArray respectively. For example, we can import rrule of f(x::Real, y::Array) like below:\n\nReverseDiff.@grad_from_chainrules f(x::TrackedReal, y::TrackedArray)\nReverseDiff.@grad_from_chainrules f(x::TrackedReal, y::Array)\nReverseDiff.@grad_from_chainrules f(x::Real, y::TrackedArray)\n\n\n\n\n\n","category":"macro"},{"location":"#ReverseDiff.jl","page":"Home","title":"ReverseDiff.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This documentation provides a specification of ReverseDiff's API, tips for usage, and details about the package's implementation.","category":"page"},{"location":"","page":"Home","title":"Home","text":"For a basic introduction to ReverseDiff, see the package's README.","category":"page"},{"location":"","page":"Home","title":"Home","text":"For usage examples, see the examples directory.","category":"page"}]
}
